# SAQUET: Scalable Automatic Question Usability Evaluation Toolkit

## Demo
Try out a very basic gpt-4o version here: [https://saquet.streamlit.app/](https://saquet.streamlit.app/)  
*Looking to update this 01-29-2024*

## About
SAQUET provides an automatic method to apply the 19-criteria Item Writing Flaws for evaluating the quality of multiple-choice questions (MCQs)!  
This toolkit aids in assessing MCQ quality effectively.

## Recent Changes
01/21/2025: Updated around half the criteria to follow a ratings-based approach, that now asks for a score 1-10 when the LLM verification happens and takes the average of three scores. Also uses gpt-4o currently. 

## Additional Information
For more details, please refer to these two papers:  
**"[An Automatic Question Usability Evaluation Toolkit](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cYweVsQAAAAJ&sortby=pubdate&citation_for_view=cYweVsQAAAAJ:hCrLmN-GePgC)"**  
**"[Assessing the Quality of Multiple-Choice Questions Using GPT-4 and Rule-Based Methods](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cYweVsQAAAAJ&sortby=pubdate&citation_for_view=cYweVsQAAAAJ:S16KYo8Pm5AC)"**  

## Contributors
- **Steven James Moore**
- **Gilles Chen**
